{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\color{green}{\\textbf{Computing the Term Frequency-Inverse Document Frequency}}$$\n",
    "$$\\small \\color{red}{\\textbf{The CopyRight @ Phuong V. Nguyen}}$$\n",
    "$$\\small \\color{blue}{\\textbf{phuong.nguyen@summer.barcelonagse.eu}}$$\n",
    "\n",
    "$$\\small \\color{green}{\\textbf{Introduction}}$$\n",
    "\n",
    "Why one needs to compute the Term Frequency-Inverse Document Frequency (TF-IDF)? This is because Machine learning algorithms cannot work with raw text directly. Rather, the text must be converted into vectors of numbers. Thus, this project aims to introduce a step-by-step procedure for converting a raw text into vectors of numbers.\n",
    "\n",
    "# Calling the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "from pickle import load\n",
    "Purple= '\\033[95m'\n",
    "Cyan= '\\033[96m'\n",
    "Darkcyan= '\\033[36m'\n",
    "Blue = '\\033[94m'\n",
    "Green = '\\033[92m'\n",
    "Yellow = '\\033[93m'\n",
    "Red = '\\033[91m'\n",
    "Bold = \"\\033[1m\"\n",
    "Reset = \"\\033[0;0m\"\n",
    "Underline= '\\033[4m'\n",
    "End = '\\033[0m'\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating documents\n",
    "In this mini project, for simplicity, we will be working with two simple documents containing one sentence each as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentA = 'the man went out for a walk'\n",
    "documentB = 'the children sat around the fire'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is worth noting that in Natural Language Processing (NLP), a common technique for extracting features from text is to place all of the words that occur in the text in a bucket. This aproach is called a $\\textbf{bag of words}$ model or $\\textbf{BoW}$ for short. \n",
    " \n",
    "# Natural Language Processing (NLP)\n",
    "## Creating a common BoW\n",
    "First, we create the separating Bow for each document above\n",
    "### Creating the separating BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBoW of the document A:\u001b[0m\n",
      "['the', 'man', 'went', 'out', 'for', 'a', 'walk']\n",
      "\u001b[1mBoW of the document B:\u001b[0m\n",
      "['the', 'children', 'sat', 'around', 'the', 'fire']\n"
     ]
    }
   ],
   "source": [
    "bagOfWordsA = documentA.split(' ')\n",
    "print(Bold+'BoW of the document A:'+End)\n",
    "print(bagOfWordsA)\n",
    "bagOfWordsB = documentB.split(' ')\n",
    "print(Bold+'BoW of the document B:'+End)\n",
    "print(bagOfWordsB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we see that BoW of both documents A and B have a number of duplicate words, such as $\\textbf{\"the\"}$. Now we will merge these two separating BoW. By doing this, we will delete any duplicate words as follows.\n",
    "\n",
    "### Merging two separating BoW as one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe comment BoWs of two documents:\u001b[0m\n",
      "{'around', 'went', 'walk', 'sat', 'the', 'children', 'fire', 'man', 'for', 'a', 'out'}\n"
     ]
    }
   ],
   "source": [
    "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB))\n",
    "print(Bold+'The comment BoWs of two documents:'+End)\n",
    "print(uniqueWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll create a dictionary of words and their occurence for each document in the corpus (collection of documents).\n",
    "### Creating the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
    "for i in bagOfWordsA:\n",
    "    numOfWordsA[i] += 1\n",
    "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
    "for i in bagOfWordsB:\n",
    "    numOfWordsB[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>around</th>\n",
       "      <th>went</th>\n",
       "      <th>walk</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "      <th>children</th>\n",
       "      <th>fire</th>\n",
       "      <th>man</th>\n",
       "      <th>for</th>\n",
       "      <th>a</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   around  went  walk  sat  the  children  fire  man  for  a  out\n",
       "0       0     1     1    0    1         0     0    1    1  1    1\n",
       "1       1     0     0    1    2         1     1    0    0  0    0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db=pd.DataFrame([numOfWordsB])\n",
    "da=pd.DataFrame([numOfWordsA])\n",
    "corpus = da.append(db, ignore_index=True)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another problem with the bag of words approach is that it doesn’t account for noise. In other words, certain words are used to formulate sentences but do not add any semantic meaning to the text. For example, the most commonly used word in the english language is the which represents 7% of all words written or spoken. You couldn’t make deduce anything about a text given the fact that it contains the word the. On the other hand, words like good and awesome could be used to determine whether a rating was positive or not. In natural language processing, useless words are referred to as stop words.\n",
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe number of useless words in English\u001b[0m\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/phuong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "print(Bold+'The number of useless words in English'+End)\n",
    "print(stopwords.words('English'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically when building a model for analynize text, we will remove all of stop words.Another strategy is to score the relative importance of words using TF-IDF.\n",
    "# Term Frequency - Inverse Document Frequency\n",
    "## Term frequency\n",
    "The number of times a word appears in a document divded by the total number of words in this document. Every document has its own term frequency\n",
    "\n",
    "$$TF_{i,j}=\\frac{n_{i,j}}{\\sum_{k}n_{i,j}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe Term Frequency:\u001b[1m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>around</th>\n",
       "      <th>went</th>\n",
       "      <th>walk</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "      <th>children</th>\n",
       "      <th>fire</th>\n",
       "      <th>man</th>\n",
       "      <th>for</th>\n",
       "      <th>a</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     around      went      walk       sat       the  children      fire  \\\n",
       "0  0.000000  0.142857  0.142857  0.000000  0.142857  0.000000  0.000000   \n",
       "1  0.166667  0.000000  0.000000  0.166667  0.333333  0.166667  0.166667   \n",
       "\n",
       "        man       for         a       out  \n",
       "0  0.142857  0.142857  0.142857  0.142857  \n",
       "1  0.000000  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfA = computeTF(numOfWordsA, bagOfWordsA)\n",
    "tfB = computeTF(numOfWordsB, bagOfWordsB)\n",
    "\n",
    "TF=pd.DataFrame([tfA ])\n",
    "TF=TF.append(tfB, ignore_index=True)\n",
    "print(Bold+'The Term Frequency:'+Bold)\n",
    "TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency\n",
    "\n",
    "Inverse data frequency determines the weight of unique words across all documents in the corpus.\n",
    "$$IDF(w)=log(\\frac{N}{df_{t}}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe Inverse Document Frequency\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>around</th>\n",
       "      <th>went</th>\n",
       "      <th>walk</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "      <th>children</th>\n",
       "      <th>fire</th>\n",
       "      <th>man</th>\n",
       "      <th>for</th>\n",
       "      <th>a</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     around      went      walk       sat  the  children      fire       man  \\\n",
       "0  0.693147  0.693147  0.693147  0.693147  0.0  0.693147  0.693147  0.693147   \n",
       "\n",
       "        for         a       out  \n",
       "0  0.693147  0.693147  0.693147  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs = computeIDF([numOfWordsA, numOfWordsB])\n",
    "print(Bold+'The Inverse Document Frequency'+End)\n",
    "IDF=pd.DataFrame([idfs])\n",
    "IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "$$TFIDF=TF_{i,j}*IDF_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe Term Frequecy Inverse Document Frequency\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>around</th>\n",
       "      <th>went</th>\n",
       "      <th>walk</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "      <th>children</th>\n",
       "      <th>fire</th>\n",
       "      <th>man</th>\n",
       "      <th>for</th>\n",
       "      <th>a</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.099021</td>\n",
       "      <td>0.099021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     around      went      walk       sat  the  children      fire       man  \\\n",
       "0  0.000000  0.099021  0.099021  0.000000  0.0  0.000000  0.000000  0.099021   \n",
       "1  0.115525  0.000000  0.000000  0.115525  0.0  0.115525  0.115525  0.000000   \n",
       "\n",
       "        for         a       out  \n",
       "0  0.099021  0.099021  0.099021  \n",
       "1  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfA = computeTFIDF(tfA, idfs)\n",
    "tfidfB = computeTFIDF(tfB, idfs)\n",
    "print(Bold+'The Term Frequecy Inverse Document Frequency'+End)\n",
    "tfidf = pd.DataFrame([tfidfA, tfidfB])\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe values of TF-IDF:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>around</th>\n",
       "      <th>children</th>\n",
       "      <th>fire</th>\n",
       "      <th>for</th>\n",
       "      <th>man</th>\n",
       "      <th>out</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "      <th>walk</th>\n",
       "      <th>went</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303216</td>\n",
       "      <td>0.42616</td>\n",
       "      <td>0.42616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.407401</td>\n",
       "      <td>0.407401</td>\n",
       "      <td>0.407401</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.407401</td>\n",
       "      <td>0.579739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     around  children      fire      for      man      out       sat  \\\n",
       "0  0.000000  0.000000  0.000000  0.42616  0.42616  0.42616  0.000000   \n",
       "1  0.407401  0.407401  0.407401  0.00000  0.00000  0.00000  0.407401   \n",
       "\n",
       "        the     walk     went  \n",
       "0  0.303216  0.42616  0.42616  \n",
       "1  0.579739  0.00000  0.00000  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([documentA, documentB])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "tfidf_sk = pd.DataFrame(denselist, columns=feature_names)\n",
    "print(Bold+'The values of TF-IDF:'+End)\n",
    "tfidf_sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values differ slightly because sklearn uses a smoothed version idf and various other little optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
